{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.utils import clip_grad_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dictionary(object):\n",
    "    def __init__(self):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.idx = 0\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2idx:\n",
    "            self.word2idx[word] = self.idx\n",
    "            self.idx2word[self.idx] = word\n",
    "            self.idx += 1\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextProcess(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.dictionary = Dictionary()\n",
    "\n",
    "    def get_data(self, path, batch_size=20):\n",
    "        with open(path, 'r') as f:\n",
    "            tokens = 0\n",
    "            for line in f:\n",
    "                words = line.split() + ['<eos>']\n",
    "                tokens += len(words)\n",
    "                for word in words: \n",
    "                    self.dictionary.add_word(word)  \n",
    "        #Create a 1-D tensor that contains the index of all the words in the file\n",
    "        rep_tensor = torch.LongTensor(tokens)\n",
    "        index = 0\n",
    "        with open(path, 'r') as f:\n",
    "            for line in f:\n",
    "                words = line.split() + ['<eos>']\n",
    "                for word in words:\n",
    "                    rep_tensor[index] = self.dictionary.word2idx[word]\n",
    "                    index += 1\n",
    "        #Find out how many batches we need            \n",
    "        num_batches = rep_tensor.shape[0] // batch_size     \n",
    "        print(\"rep_tensor.shape[0]: \", rep_tensor.shape[0]) #gives the total number of elements (tokens) in the tensor. This represents the total number of words (or tokens) in the dataset.\n",
    "        print(\"rep_tensor \", rep_tensor)\n",
    "        print(\"batch_size: \", batch_size)\n",
    "        print(\"num_batches: \", num_batches)\n",
    "        #Remove the remainder (Filter out the ones that don't fit)\n",
    "        rep_tensor = rep_tensor[:num_batches*batch_size]\n",
    "        # return (batch_size,num_batches)\n",
    "        rep_tensor = rep_tensor.view(batch_size, -1)\n",
    "        return rep_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 128 # Input features to the LSTM\n",
    "hidden_size = 1024 # Number of hidden units in the LSTM\n",
    "num_layers = 1 # Number of layers in the LSTM\n",
    "num_epochs = 20 # Number of epochs\n",
    "batch_size = 20 # Number of samples in a batch\n",
    "timesteps = 30 # Check 30 previous words to predict the next word\n",
    "learning_rate = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = TextProcess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rep_tensor.shape[0]:  29686\n",
      "rep_tensor  tensor([   0,    1,    2,  ...,  878, 5289,    5])\n",
      "batch_size:  20\n",
      "num_batches:  1484\n",
      "rep_tensor:  torch.Size([20, 1484])\n"
     ]
    }
   ],
   "source": [
    "rep_tensor = corpus.get_data('alice.txt', batch_size)\n",
    "# rep_tensor is the tensor that contains th eindex of all the words. Each row contains 1659 words\n",
    "print(\"rep_tensor: \", rep_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size:  5290\n",
      "Number of batches:  49\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "corpus.dictionary is a dictionary that maps words to their unique indices (e.g., word2idx in your earlier example).\n",
    "len(corpus.dictionary) gives the total number of unique words (or tokens) in the vocabulary. This is referred to as the vocabulary size.\n",
    "\"\"\"\n",
    "vocab_size = len(corpus.dictionary)\n",
    "print(\"Vocab size: \", vocab_size)\n",
    "# The total number of full batches that can be created from the dataset, considering the sequence length (rep_tensor.shape[1]) and the specified timesteps.\n",
    "num_batches = rep_tensor.shape[1] // timesteps\n",
    "print(\"Number of batches: \", num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Visual\n",
    "\"\"\" \n",
    "rep_tensor.shape = (2, 10):\n",
    "2 rows: Two sequences (Batch 1 and Batch 2).\n",
    "10 columns: Ten words in each sequence.\n",
    "timesteps = 5: Divide each sequence into chunks of 5 words.\n",
    "num_batches = 10 // 5 = 2: Two chunks (batches) of 5 words can be created from each sequence.\n",
    "Tensor Visualization (rep_tensor):\n",
    "\n",
    "Word Index\tW1\tW2\tW3\tW4\tW5\tW6\tW7\tW8\tW9\tW10\n",
    "Sequence 1\t\"The\"\t\"quick\"\t\"brown\"\t\"fox\"\t\"jumps\"\t\"over\"\t\"the\"\t\"lazy\"\t\"dog\"\t\"again\"\n",
    "Sequence 2\t\"A\"\t\"cat\"\t\"sat\"\t\"on\"\t\"the\"\t\"mat\"\t\"with\"\t\"a\"\t\"hat\"\t\"too\"\n",
    "\n",
    "Divide into Chunks of timesteps = 5\n",
    "First Chunk (timesteps = 5):\n",
    "\n",
    "We take the first 5 words (columns W1 to W5) from each sequence:\n",
    "\n",
    "Word Index\tW1\tW2\tW3\tW4\tW5\n",
    "Sequence 1\t\"The\"\t\"quick\"\t\"brown\"\t\"fox\"\t\"jumps\"\n",
    "Sequence 2\t\"A\"\t\"cat\"\t\"sat\"\t\"on\"\t\"the\"\n",
    "Second Chunk (timesteps = 5):\n",
    "\n",
    "We take the next 5 words (columns W6 to W10) from each sequence:\n",
    "\n",
    "Word Index\tW6\tW7\tW8\tW9\tW10\n",
    "Sequence 1\t\"over\"\t\"the\"\t\"lazy\"\t\"dog\"\t\"again\"\n",
    "Sequence 2\t\"mat\"\t\"with\"\t\"a\"\t\"hat\"\t\"too\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" EMBEDDING\n",
    "Tensor Visualization:\n",
    "\n",
    "Word Index\tW1\tW2\tW3\tW4\tW5\tW6\tW7\tW8\tW9\tW10\n",
    "Sequence 1\t\"The\"\t\"quick\"\t\"brown\"\t\"fox\"\t\"jumps\"\t\"over\"\t\"the\"\t\"lazy\"\t\"dog\"\t\"again\"\n",
    "Sequence 2 \"A\"\t\"cat\"\t\"sat\"\t\"on\"\t\"the\"\t\"mat\"\t\"with\"\t\"a\"\t\"hat\"\t\"too\"\n",
    "\n",
    "vocab_size = 12: The vocabulary contains the words: [\"<unk>\", \"The\", \"quick\", \"brown\", \"fox\", \"jumps\", \"over\", \"the\", \"lazy\", \"dog\", \"again\", \"cat\", \"sat\", \"on\", \"mat\", \"with\", \"a\", \"hat\", \"too\"].\n",
    "embed_size = 4: Each word will be represented as a 4-dimensional vector.\n",
    "hidden_size = 6: The LSTMâ€™s hidden state will have 6 dimensions.\n",
    "num_layers = 1: We will use a single-layer LSTM.\n",
    "\n",
    "Embedding Layer\n",
    "Input: A tensor of word indices, e.g.:\n",
    "x = [[1, 2, 3, 4, 5],  # Sequence 1: \"The quick brown fox jumps\"\n",
    "     [6, 7, 8, 9, 10]] # Sequence 2: \"over the lazy dog again\"\n",
    "Shape: (batch_size=2, seq_length=5).\n",
    "\n",
    "[[[0.1, 0.2, 0.3, 0.4],  # Embedding for \"The\"\n",
    "  [0.5, 0.6, 0.7, 0.8],  # Embedding for \"quick\"\n",
    "  ...],\n",
    " [[0.9, 0.1, 0.2, 0.3],  # Embedding for \"over\"\n",
    "  [0.4, 0.5, 0.6, 0.7],  # Embedding for \"the\"\n",
    "  ...]] \n",
    "  \n",
    "  LSTM\n",
    "\n",
    "Input: Embeddings from the previous layer ((2, 5, 4)).\n",
    "LSTM processes the sequence step by step and generates hidden states:\n",
    "Output: A tensor of hidden states for each time step:\n",
    "Shape: (2, 5, 6)  # batch_size, seq_length, hidden_size\n",
    "\n",
    "Example (simplified hidden states):\n",
    "[[[0.1, 0.3, 0.5, 0.2, 0.4, 0.6],  # Hidden state at step 1 for Sequence 1\n",
    "  [0.2, 0.4, 0.6, 0.3, 0.5, 0.7],  # Hidden state at step 2 for Sequence 1\n",
    "  ...],\n",
    " [[0.5, 0.7, 0.9, 0.6, 0.8, 0.1],  # Hidden state at step 1 for Sequence 2\n",
    "  ...]]\n",
    "\n",
    "Reshape for Linear Layer\n",
    "\n",
    "The output from the LSTM is reshaped to combine the batch_size and seq_length dimensions:\n",
    "Reshaped Output Shape: (2 * 5, 6) = (10, 6)\n",
    "Example:\n",
    "[[0.1, 0.3, 0.5, 0.2, 0.4, 0.6],  # Flattened hidden state\n",
    " [0.2, 0.4, 0.6, 0.3, 0.5, 0.7],\n",
    " ...]\n",
    "\n",
    " Linear Layer\n",
    "\n",
    "Input: Flattened LSTM output ((10, 6)).\n",
    "Output: Predicted scores for the next word in the vocabulary:\n",
    "Shape: (10, vocab_size=12)  # One score per word in the vocabulary\n",
    "Example (simplified scores for 3 words):\n",
    "[[0.2, 0.1, 0.05, 0.8, 0.3, 0.4, ...],  # Scores for all 12 words\n",
    " [0.3, 0.2, 0.1, 0.7, 0.4, 0.2, ...],\n",
    " ...]\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers):\n",
    "        super(TextGenerator, self).__init__()\n",
    "        # If your embedding_size is 200, then each word would be represented by a dense vector of 200 values.\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size) # EMBEDDING LAYER is used to convert the word indices into word vectors.\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True) # LSTM LAYER is used to process the word vectors and generate the hidden states.\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size) # LINEAR LAYER is used to convert the hidden states into word predictions.\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        # Perform word embedding\n",
    "        x = self.embed(x)\n",
    "        # Reshape the input tensor\n",
    "        #x = x.view(batch_size, timesteps, embed_size)\n",
    "        out, (h, c) = self.lstm(x, h)\n",
    "        # Reshape the output from (samples, timesteps, output_features) to a shape appropriate for the FC layer (samples*timesteps, output_features)\n",
    "        out = out.reshape(out.size(0)*out.size(1), out.size(2))\n",
    "        # Decode hidden states of all time steps\n",
    "        out = self.linear(out)\n",
    "        return out, (h, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextGenerator(vocab_size, embed_size, hidden_size, num_layers)\n",
    "\n",
    "loss_fun = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nz/yx4776yn66n8sjwvrtfd_w3r0000gn/T/ipykernel_4768/453646080.py:20: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  clip_grad_norm(model.parameters(), 0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 8.5761\n",
      "Epoch [2/20], Loss: 6.0195\n",
      "Epoch [3/20], Loss: 5.2330\n",
      "Epoch [4/20], Loss: 4.7457\n",
      "Epoch [5/20], Loss: 4.1741\n",
      "Epoch [6/20], Loss: 3.7214\n",
      "Epoch [7/20], Loss: 3.3206\n",
      "Epoch [8/20], Loss: 2.9692\n",
      "Epoch [9/20], Loss: 2.5691\n",
      "Epoch [10/20], Loss: 2.2565\n",
      "Epoch [11/20], Loss: 1.9041\n",
      "Epoch [12/20], Loss: 1.5915\n",
      "Epoch [13/20], Loss: 1.3059\n",
      "Epoch [14/20], Loss: 1.0712\n",
      "Epoch [15/20], Loss: 0.8878\n",
      "Epoch [16/20], Loss: 0.6262\n",
      "Epoch [17/20], Loss: 0.3834\n",
      "Epoch [18/20], Loss: 0.2881\n",
      "Epoch [19/20], Loss: 0.1945\n",
      "Epoch [20/20], Loss: 0.1182\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # Set initial hidden and cell states\n",
    "    states = (torch.zeros(num_layers, batch_size, hidden_size),\n",
    "              torch.zeros(num_layers, batch_size, hidden_size))\n",
    "    \n",
    "    for i in range(0, rep_tensor.size(1) - timesteps, timesteps):\n",
    "        # Get mini-batch inputs and targets\n",
    "        inputs = rep_tensor[:, i:i+timesteps] # --> (:, 0:0+timestep) Outputs --> (:, 1:1+timestep) and so on\n",
    "        targets = rep_tensor[:, (i+1):(i+1)+timesteps]\n",
    "        #String: \"Black hourse is here\"\n",
    "        #Input: \"Black hourse\" Output \" lack hourse i\". Our output is actually a delay of our input. So it's not including the B. So it's a delay by one element.\n",
    "        outputs, _ = model(inputs, states)\n",
    "        loss = loss_fun(outputs, targets.reshape(-1)) #target should be one dimension so we reshape it\n",
    "\n",
    "        # Backpropagation and Weight Update\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        # Perform Gradient Clipping .clip_value (float or int) â€“ The maximum value of the elements of the input tensor.\n",
    "        # The gradients are clipped in the range [-clip_value, clip_value]. This is to prevent the exploding gradient problem.\n",
    "        clip_grad_norm(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        step = (i+1) // timesteps\n",
    "        if step % 100 == 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))   \n",
    "                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5290])\n",
      "4099\n",
      "torch.Size([1, 5290])\n",
      "20\n",
      "torch.Size([1, 5290])\n",
      "27\n",
      "torch.Size([1, 5290])\n",
      "28\n",
      "torch.Size([1, 5290])\n",
      "262\n",
      "torch.Size([1, 5290])\n",
      "95\n",
      "torch.Size([1, 5290])\n",
      "13\n",
      "torch.Size([1, 5290])\n",
      "44\n",
      "torch.Size([1, 5290])\n",
      "4441\n",
      "torch.Size([1, 5290])\n",
      "320\n",
      "torch.Size([1, 5290])\n",
      "74\n",
      "torch.Size([1, 5290])\n",
      "110\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "3968\n",
      "torch.Size([1, 5290])\n",
      "38\n",
      "torch.Size([1, 5290])\n",
      "16\n",
      "torch.Size([1, 5290])\n",
      "390\n",
      "torch.Size([1, 5290])\n",
      "13\n",
      "torch.Size([1, 5290])\n",
      "44\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "6\n",
      "torch.Size([1, 5290])\n",
      "262\n",
      "torch.Size([1, 5290])\n",
      "95\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "2204\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "858\n",
      "torch.Size([1, 5290])\n",
      "20\n",
      "torch.Size([1, 5290])\n",
      "6\n",
      "torch.Size([1, 5290])\n",
      "333\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "1284\n",
      "torch.Size([1, 5290])\n",
      "1091\n",
      "torch.Size([1, 5290])\n",
      "2628\n",
      "torch.Size([1, 5290])\n",
      "112\n",
      "torch.Size([1, 5290])\n",
      "22\n",
      "torch.Size([1, 5290])\n",
      "28\n",
      "torch.Size([1, 5290])\n",
      "262\n",
      "torch.Size([1, 5290])\n",
      "95\n",
      "torch.Size([1, 5290])\n",
      "13\n",
      "torch.Size([1, 5290])\n",
      "1552\n",
      "torch.Size([1, 5290])\n",
      "38\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "4772\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "1054\n",
      "torch.Size([1, 5290])\n",
      "2521\n",
      "torch.Size([1, 5290])\n",
      "57\n",
      "torch.Size([1, 5290])\n",
      "44\n",
      "torch.Size([1, 5290])\n",
      "4441\n",
      "torch.Size([1, 5290])\n",
      "207\n",
      "torch.Size([1, 5290])\n",
      "6\n",
      "torch.Size([1, 5290])\n",
      "129\n",
      "torch.Size([1, 5290])\n",
      "1782\n",
      "torch.Size([1, 5290])\n",
      "143\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "1981\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "9\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "116\n",
      "torch.Size([1, 5290])\n",
      "930\n",
      "torch.Size([1, 5290])\n",
      "1533\n",
      "torch.Size([1, 5290])\n",
      "5057\n",
      "torch.Size([1, 5290])\n",
      "3803\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "4033\n",
      "torch.Size([1, 5290])\n",
      "2584\n",
      "torch.Size([1, 5290])\n",
      "34\n",
      "torch.Size([1, 5290])\n",
      "7\n",
      "torch.Size([1, 5290])\n",
      "44\n",
      "torch.Size([1, 5290])\n",
      "1228\n",
      "torch.Size([1, 5290])\n",
      "174\n",
      "torch.Size([1, 5290])\n",
      "55\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "887\n",
      "torch.Size([1, 5290])\n",
      "320\n",
      "torch.Size([1, 5290])\n",
      "1815\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "3225\n",
      "torch.Size([1, 5290])\n",
      "38\n",
      "torch.Size([1, 5290])\n",
      "207\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "3968\n",
      "torch.Size([1, 5290])\n",
      "20\n",
      "torch.Size([1, 5290])\n",
      "427\n",
      "torch.Size([1, 5290])\n",
      "11\n",
      "torch.Size([1, 5290])\n",
      "1452\n",
      "torch.Size([1, 5290])\n",
      "290\n",
      "torch.Size([1, 5290])\n",
      "13\n",
      "torch.Size([1, 5290])\n",
      "1054\n",
      "torch.Size([1, 5290])\n",
      "2183\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "3225\n",
      "torch.Size([1, 5290])\n",
      "618\n",
      "torch.Size([1, 5290])\n",
      "930\n",
      "torch.Size([1, 5290])\n",
      "7\n",
      "torch.Size([1, 5290])\n",
      "150\n",
      "torch.Size([1, 5290])\n",
      "114\n",
      "Sampled [100/500] words and save to output.txt\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "27\n",
      "torch.Size([1, 5290])\n",
      "362\n",
      "torch.Size([1, 5290])\n",
      "389\n",
      "torch.Size([1, 5290])\n",
      "20\n",
      "torch.Size([1, 5290])\n",
      "35\n",
      "torch.Size([1, 5290])\n",
      "2678\n",
      "torch.Size([1, 5290])\n",
      "16\n",
      "torch.Size([1, 5290])\n",
      "980\n",
      "torch.Size([1, 5290])\n",
      "4789\n",
      "torch.Size([1, 5290])\n",
      "882\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "776\n",
      "torch.Size([1, 5290])\n",
      "103\n",
      "torch.Size([1, 5290])\n",
      "93\n",
      "torch.Size([1, 5290])\n",
      "1388\n",
      "torch.Size([1, 5290])\n",
      "16\n",
      "torch.Size([1, 5290])\n",
      "2756\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "413\n",
      "torch.Size([1, 5290])\n",
      "1605\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "2204\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "317\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "603\n",
      "torch.Size([1, 5290])\n",
      "1115\n",
      "torch.Size([1, 5290])\n",
      "1054\n",
      "torch.Size([1, 5290])\n",
      "4185\n",
      "torch.Size([1, 5290])\n",
      "27\n",
      "torch.Size([1, 5290])\n",
      "272\n",
      "torch.Size([1, 5290])\n",
      "6\n",
      "torch.Size([1, 5290])\n",
      "7\n",
      "torch.Size([1, 5290])\n",
      "22\n",
      "torch.Size([1, 5290])\n",
      "375\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "84\n",
      "torch.Size([1, 5290])\n",
      "42\n",
      "torch.Size([1, 5290])\n",
      "13\n",
      "torch.Size([1, 5290])\n",
      "1054\n",
      "torch.Size([1, 5290])\n",
      "2183\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "366\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "16\n",
      "torch.Size([1, 5290])\n",
      "390\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "160\n",
      "torch.Size([1, 5290])\n",
      "6\n",
      "torch.Size([1, 5290])\n",
      "7\n",
      "torch.Size([1, 5290])\n",
      "1054\n",
      "torch.Size([1, 5290])\n",
      "4185\n",
      "torch.Size([1, 5290])\n",
      "272\n",
      "torch.Size([1, 5290])\n",
      "1649\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "2974\n",
      "torch.Size([1, 5290])\n",
      "9\n",
      "torch.Size([1, 5290])\n",
      "98\n",
      "torch.Size([1, 5290])\n",
      "34\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "303\n",
      "torch.Size([1, 5290])\n",
      "3402\n",
      "torch.Size([1, 5290])\n",
      "1933\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "253\n",
      "torch.Size([1, 5290])\n",
      "251\n",
      "torch.Size([1, 5290])\n",
      "34\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "3830\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "107\n",
      "torch.Size([1, 5290])\n",
      "329\n",
      "torch.Size([1, 5290])\n",
      "4755\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "518\n",
      "torch.Size([1, 5290])\n",
      "4738\n",
      "torch.Size([1, 5290])\n",
      "7\n",
      "torch.Size([1, 5290])\n",
      "150\n",
      "torch.Size([1, 5290])\n",
      "114\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "4156\n",
      "torch.Size([1, 5290])\n",
      "114\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "898\n",
      "torch.Size([1, 5290])\n",
      "781\n",
      "torch.Size([1, 5290])\n",
      "762\n",
      "torch.Size([1, 5290])\n",
      "272\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "3225\n",
      "Sampled [200/500] words and save to output.txt\n",
      "torch.Size([1, 5290])\n",
      "38\n",
      "torch.Size([1, 5290])\n",
      "44\n",
      "torch.Size([1, 5290])\n",
      "1228\n",
      "torch.Size([1, 5290])\n",
      "564\n",
      "torch.Size([1, 5290])\n",
      "27\n",
      "torch.Size([1, 5290])\n",
      "60\n",
      "torch.Size([1, 5290])\n",
      "95\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "22\n",
      "torch.Size([1, 5290])\n",
      "28\n",
      "torch.Size([1, 5290])\n",
      "44\n",
      "torch.Size([1, 5290])\n",
      "1228\n",
      "torch.Size([1, 5290])\n",
      "3569\n",
      "torch.Size([1, 5290])\n",
      "30\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "4680\n",
      "torch.Size([1, 5290])\n",
      "1001\n",
      "torch.Size([1, 5290])\n",
      "103\n",
      "torch.Size([1, 5290])\n",
      "4924\n",
      "torch.Size([1, 5290])\n",
      "25\n",
      "torch.Size([1, 5290])\n",
      "2971\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "6\n",
      "torch.Size([1, 5290])\n",
      "38\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "5239\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "413\n",
      "torch.Size([1, 5290])\n",
      "1308\n",
      "torch.Size([1, 5290])\n",
      "28\n",
      "torch.Size([1, 5290])\n",
      "44\n",
      "torch.Size([1, 5290])\n",
      "1228\n",
      "torch.Size([1, 5290])\n",
      "272\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "4772\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "5234\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "285\n",
      "torch.Size([1, 5290])\n",
      "2546\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "1368\n",
      "torch.Size([1, 5290])\n",
      "367\n",
      "torch.Size([1, 5290])\n",
      "4204\n",
      "torch.Size([1, 5290])\n",
      "574\n",
      "torch.Size([1, 5290])\n",
      "9\n",
      "torch.Size([1, 5290])\n",
      "236\n",
      "torch.Size([1, 5290])\n",
      "265\n",
      "torch.Size([1, 5290])\n",
      "1909\n",
      "torch.Size([1, 5290])\n",
      "103\n",
      "torch.Size([1, 5290])\n",
      "3769\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "1697\n",
      "torch.Size([1, 5290])\n",
      "7\n",
      "torch.Size([1, 5290])\n",
      "38\n",
      "torch.Size([1, 5290])\n",
      "44\n",
      "torch.Size([1, 5290])\n",
      "1228\n",
      "torch.Size([1, 5290])\n",
      "3319\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "2836\n",
      "torch.Size([1, 5290])\n",
      "534\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "426\n",
      "torch.Size([1, 5290])\n",
      "7\n",
      "torch.Size([1, 5290])\n",
      "173\n",
      "torch.Size([1, 5290])\n",
      "186\n",
      "torch.Size([1, 5290])\n",
      "80\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "3161\n",
      "torch.Size([1, 5290])\n",
      "3209\n",
      "torch.Size([1, 5290])\n",
      "627\n",
      "torch.Size([1, 5290])\n",
      "628\n",
      "torch.Size([1, 5290])\n",
      "2307\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "22\n",
      "torch.Size([1, 5290])\n",
      "375\n",
      "torch.Size([1, 5290])\n",
      "27\n",
      "torch.Size([1, 5290])\n",
      "28\n",
      "torch.Size([1, 5290])\n",
      "44\n",
      "torch.Size([1, 5290])\n",
      "532\n",
      "torch.Size([1, 5290])\n",
      "103\n",
      "torch.Size([1, 5290])\n",
      "843\n",
      "torch.Size([1, 5290])\n",
      "69\n",
      "torch.Size([1, 5290])\n",
      "1194\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "367\n",
      "torch.Size([1, 5290])\n",
      "4369\n",
      "torch.Size([1, 5290])\n",
      "1054\n",
      "torch.Size([1, 5290])\n",
      "4185\n",
      "torch.Size([1, 5290])\n",
      "7\n",
      "torch.Size([1, 5290])\n",
      "22\n",
      "torch.Size([1, 5290])\n",
      "375\n",
      "torch.Size([1, 5290])\n",
      "192\n",
      "torch.Size([1, 5290])\n",
      "9\n",
      "Sampled [300/500] words and save to output.txt\n",
      "torch.Size([1, 5290])\n",
      "262\n",
      "torch.Size([1, 5290])\n",
      "95\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "285\n",
      "torch.Size([1, 5290])\n",
      "137\n",
      "torch.Size([1, 5290])\n",
      "9\n",
      "torch.Size([1, 5290])\n",
      "552\n",
      "torch.Size([1, 5290])\n",
      "483\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "497\n",
      "torch.Size([1, 5290])\n",
      "35\n",
      "torch.Size([1, 5290])\n",
      "2678\n",
      "torch.Size([1, 5290])\n",
      "72\n",
      "torch.Size([1, 5290])\n",
      "73\n",
      "torch.Size([1, 5290])\n",
      "20\n",
      "torch.Size([1, 5290])\n",
      "6\n",
      "torch.Size([1, 5290])\n",
      "333\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "1457\n",
      "torch.Size([1, 5290])\n",
      "3607\n",
      "torch.Size([1, 5290])\n",
      "20\n",
      "torch.Size([1, 5290])\n",
      "2593\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "366\n",
      "torch.Size([1, 5290])\n",
      "4535\n",
      "torch.Size([1, 5290])\n",
      "27\n",
      "torch.Size([1, 5290])\n",
      "209\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "3225\n",
      "torch.Size([1, 5290])\n",
      "38\n",
      "torch.Size([1, 5290])\n",
      "44\n",
      "torch.Size([1, 5290])\n",
      "3758\n",
      "torch.Size([1, 5290])\n",
      "73\n",
      "torch.Size([1, 5290])\n",
      "20\n",
      "torch.Size([1, 5290])\n",
      "129\n",
      "torch.Size([1, 5290])\n",
      "73\n",
      "torch.Size([1, 5290])\n",
      "9\n",
      "torch.Size([1, 5290])\n",
      "98\n",
      "torch.Size([1, 5290])\n",
      "150\n",
      "torch.Size([1, 5290])\n",
      "114\n",
      "torch.Size([1, 5290])\n",
      "44\n",
      "torch.Size([1, 5290])\n",
      "1233\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "20\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "2042\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "798\n",
      "torch.Size([1, 5290])\n",
      "20\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "3118\n",
      "torch.Size([1, 5290])\n",
      "3119\n",
      "torch.Size([1, 5290])\n",
      "27\n",
      "torch.Size([1, 5290])\n",
      "60\n",
      "torch.Size([1, 5290])\n",
      "1737\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "253\n",
      "torch.Size([1, 5290])\n",
      "13\n",
      "torch.Size([1, 5290])\n",
      "1552\n",
      "torch.Size([1, 5290])\n",
      "38\n",
      "torch.Size([1, 5290])\n",
      "44\n",
      "torch.Size([1, 5290])\n",
      "1289\n",
      "torch.Size([1, 5290])\n",
      "27\n",
      "torch.Size([1, 5290])\n",
      "28\n",
      "torch.Size([1, 5290])\n",
      "35\n",
      "torch.Size([1, 5290])\n",
      "43\n",
      "torch.Size([1, 5290])\n",
      "38\n",
      "torch.Size([1, 5290])\n",
      "207\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "3225\n",
      "torch.Size([1, 5290])\n",
      "288\n",
      "torch.Size([1, 5290])\n",
      "103\n",
      "torch.Size([1, 5290])\n",
      "843\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "27\n",
      "torch.Size([1, 5290])\n",
      "42\n",
      "torch.Size([1, 5290])\n",
      "3523\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "2204\n",
      "torch.Size([1, 5290])\n",
      "16\n",
      "torch.Size([1, 5290])\n",
      "390\n",
      "torch.Size([1, 5290])\n",
      "13\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "96\n",
      "torch.Size([1, 5290])\n",
      "1274\n",
      "torch.Size([1, 5290])\n",
      "167\n",
      "torch.Size([1, 5290])\n",
      "9\n",
      "torch.Size([1, 5290])\n",
      "236\n",
      "torch.Size([1, 5290])\n",
      "265\n",
      "torch.Size([1, 5290])\n",
      "1909\n",
      "torch.Size([1, 5290])\n",
      "34\n",
      "torch.Size([1, 5290])\n",
      "933\n",
      "torch.Size([1, 5290])\n",
      "9\n",
      "torch.Size([1, 5290])\n",
      "1054\n",
      "torch.Size([1, 5290])\n",
      "2446\n",
      "torch.Size([1, 5290])\n",
      "80\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "518\n",
      "Sampled [400/500] words and save to output.txt\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "898\n",
      "torch.Size([1, 5290])\n",
      "781\n",
      "torch.Size([1, 5290])\n",
      "103\n",
      "torch.Size([1, 5290])\n",
      "843\n",
      "torch.Size([1, 5290])\n",
      "627\n",
      "torch.Size([1, 5290])\n",
      "628\n",
      "torch.Size([1, 5290])\n",
      "1115\n",
      "torch.Size([1, 5290])\n",
      "95\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "27\n",
      "torch.Size([1, 5290])\n",
      "3757\n",
      "torch.Size([1, 5290])\n",
      "9\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "1528\n",
      "torch.Size([1, 5290])\n",
      "569\n",
      "torch.Size([1, 5290])\n",
      "44\n",
      "torch.Size([1, 5290])\n",
      "4619\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "1457\n",
      "torch.Size([1, 5290])\n",
      "3607\n",
      "torch.Size([1, 5290])\n",
      "13\n",
      "torch.Size([1, 5290])\n",
      "44\n",
      "torch.Size([1, 5290])\n",
      "2986\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "80\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "253\n",
      "torch.Size([1, 5290])\n",
      "13\n",
      "torch.Size([1, 5290])\n",
      "1585\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "1060\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "22\n",
      "torch.Size([1, 5290])\n",
      "28\n",
      "torch.Size([1, 5290])\n",
      "44\n",
      "torch.Size([1, 5290])\n",
      "2986\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "836\n",
      "torch.Size([1, 5290])\n",
      "103\n",
      "torch.Size([1, 5290])\n",
      "3307\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "600\n",
      "torch.Size([1, 5290])\n",
      "3020\n",
      "torch.Size([1, 5290])\n",
      "2688\n",
      "torch.Size([1, 5290])\n",
      "930\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "1457\n",
      "torch.Size([1, 5290])\n",
      "3607\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "95\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "898\n",
      "torch.Size([1, 5290])\n",
      "781\n",
      "torch.Size([1, 5290])\n",
      "93\n",
      "torch.Size([1, 5290])\n",
      "1388\n",
      "torch.Size([1, 5290])\n",
      "1790\n",
      "torch.Size([1, 5290])\n",
      "80\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "43\n",
      "torch.Size([1, 5290])\n",
      "212\n",
      "torch.Size([1, 5290])\n",
      "44\n",
      "torch.Size([1, 5290])\n",
      "4619\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "3832\n",
      "torch.Size([1, 5290])\n",
      "95\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "426\n",
      "torch.Size([1, 5290])\n",
      "7\n",
      "torch.Size([1, 5290])\n",
      "300\n",
      "torch.Size([1, 5290])\n",
      "34\n",
      "torch.Size([1, 5290])\n",
      "7\n",
      "torch.Size([1, 5290])\n",
      "150\n",
      "torch.Size([1, 5290])\n",
      "114\n",
      "torch.Size([1, 5290])\n",
      "1649\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "46\n",
      "torch.Size([1, 5290])\n",
      "1649\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "20\n",
      "torch.Size([1, 5290])\n",
      "35\n",
      "torch.Size([1, 5290])\n",
      "2678\n",
      "torch.Size([1, 5290])\n",
      "16\n",
      "torch.Size([1, 5290])\n",
      "116\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "2474\n",
      "torch.Size([1, 5290])\n",
      "856\n",
      "torch.Size([1, 5290])\n",
      "7\n",
      "torch.Size([1, 5290])\n",
      "150\n",
      "torch.Size([1, 5290])\n",
      "114\n",
      "torch.Size([1, 5290])\n",
      "44\n",
      "torch.Size([1, 5290])\n",
      "1396\n",
      "torch.Size([1, 5290])\n",
      "20\n",
      "torch.Size([1, 5290])\n",
      "427\n",
      "torch.Size([1, 5290])\n",
      "11\n",
      "torch.Size([1, 5290])\n",
      "1667\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "Sampled [500/500] words and save to output.txt\n"
     ]
    }
   ],
   "source": [
    "#Test Model\n",
    "with torch.no_grad():\n",
    "    with open('output.txt', 'w') as f:\n",
    "        # Set initial hidden ane cell states\n",
    "        state = (torch.zeros(num_layers, 1, hidden_size),\n",
    "                 torch.zeros(num_layers, 1, hidden_size)) #batch_size = 1 because we testing not training \n",
    "        \n",
    "        # Select one word id randomly and convert it to shape (1, 1)\n",
    "        input = torch.randint(0, vocab_size, (1,)).long().unsqueeze(1)\n",
    "        \n",
    "        for i in range(500):\n",
    "            # Forward propagate RNN\n",
    "            output, _ = model(input, state)\n",
    "            print(output.shape)\n",
    "            # Sample a word id from the exponential of the output. This is the probability distribution of the next word.\n",
    "            prob = output.exp()\n",
    "            word_id = torch.multinomial(prob, num_samples=1).item()\n",
    "            print(word_id)\n",
    "            # Fill input with sampled word id for the next time step\n",
    "            input.fill_(word_id)\n",
    "            \n",
    "            # File write\n",
    "            word = corpus.dictionary.idx2word[word_id]\n",
    "            word = '\\n' if word == '<eos>' else word + ' '\n",
    "            f.write(word)\n",
    "            \n",
    "            if (i+1) % 100 == 0:\n",
    "                print('Sampled [{}/{}] words and save to {}'.format(i+1, 500, 'output.txt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
