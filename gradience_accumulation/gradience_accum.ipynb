{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet101()\n",
    "num_iterations = 10\n",
    "xe = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 5e-4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Original code\n",
    "batch_size = 1000\n",
    "for i in range(num_iterations):\n",
    "  inputs = torch.rand((batch_size, 3, 224, 224))\n",
    "  labels = torch.LongTensor(batch_size).random_(0, 100)\n",
    "  outputs = model(inputs)\n",
    "  loss = xe(outputs, labels)\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  optimizer.zero_grad()\n",
    "  print(\"Done with batch\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "decired_batch_size = 100\n",
    "tolerated_batch_size = 50\n",
    "accum_steps = decired_batch_size / tolerated_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Gradient accumulate\n",
    "\"\"\"\n",
    "for i in range(num_iterations):\n",
    "  inputs = torch.rand((tolerated_batch_size, 3, 224, 224))\n",
    "  labels = torch.LongTensor(tolerated_batch_size).random_(0, 100)\n",
    "  outputs = model(inputs)\n",
    "  loss = xe(outputs, labels)\n",
    "  loss = loss / accum_steps\n",
    "  loss.backward()\n",
    "  if (i+1) % accum_steps == 0:\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    print(\"Done with batch\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
