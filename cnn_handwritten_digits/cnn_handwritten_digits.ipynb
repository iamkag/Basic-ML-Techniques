{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_gray = 0.1307\n",
    "stddev_gray = 0.3081\n",
    "\n",
    "# Data normalization\n",
    "# input[channel] = (input[channel] - mean[channel]) / std[channel]\n",
    "\n",
    "trs = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((mean_gray,), (stddev_gray,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST( root = './data', train = True, transform = trs, download=True)\n",
    "test_dataset = datasets.MNIST( root = './data', train = False, transform = trs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check a random image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "random_img = train_dataset[20][0].numpy()*stddev_gray + mean_gray #Denormalize\n",
    "plt.imshow(random_img.reshape(28,28), cmap = 'gray')\n",
    "print(train_dataset[20][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "\n",
    "\n",
    "batch_size = 100\n",
    "train_load = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_load = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CNN\n",
    "# CMNN1: 8 feature maps, 3x3 filters --> Max Pooling (feature maps size /2) --> CNN2: 32 feature maps --> Max Pooling --> FC1 600 output neurons --> FC2 Classifcation layer (10 classes)\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super( CNN, self ).__init__()\n",
    "        #**** CNN1\n",
    "        #grayscale images have 1 channel, kernel -> filter size, padding --> same padding of input_size == output_size (filter_size-1)/2\n",
    "        #output_size of each of the eight feature maps= [(input_size - filter_size +2*padding)/stride+1 ]= (28-3+2)/1+1 =28\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, stride=1, padding =1) \n",
    "        #batch normalization\n",
    "        self.batchnorm1 = nn.BatchNorm2d(8)\n",
    "        self.relu = nn.ReLU()\n",
    "        #max pooling\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2)\n",
    "        #output size = 28/2 =14\n",
    "        #**** CNN2\n",
    "        #same padding = (filetr_size-1) / 2 = (5-1)/2 =2\n",
    "        self.cnn2 = nn.Conv2d(in_channels=8, out_channels=32, kernel_size=5, stride=1, padding =2) \n",
    "        #output size of each of 32 feature maps [(14-5+2*2)/1+1] = 14\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
    "        #Linear layers\n",
    "        #Flatten 32 feature maps, each feature map is of size 7*7 : 7*7*32 = 1568\n",
    "        self.fc1 = nn.Linear(1568, 600)\n",
    "        self.dropout = nn.Dropout(p = 0.5) # 0.5->> drop the neurons by 50%\n",
    "        self.fc2 = nn.Linear(600,10) #classification layer\n",
    "\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = self.cnn1(x)\n",
    "        out = self.batchnorm1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.cnn2(out)\n",
    "        out = self.batchnorm2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "\n",
    "        #Flatten the 32 feature maps from MaxPooling to feed it to the FC1 layer\n",
    "        #out = self.view(batch_size, 1568)\n",
    "        out = out.view(-1, 1568)\n",
    "\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the model\n",
    "model = CNN()\n",
    "CUDA = torch.cuda.is_available() # check for GPU\n",
    "\n",
    "if CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr= 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1/10, Training Loss: 0.137, Testing Loss: 0.824, Train Accuracy: 0.961, Test Accuracy: 0.984  \n",
      "Epoch2/10, Training Loss: 0.094, Testing Loss: 0.564, Train Accuracy: 0.972, Test Accuracy: 0.985  \n",
      "Epoch3/10, Training Loss: 0.074, Testing Loss: 0.444, Train Accuracy: 0.980, Test Accuracy: 0.988  \n",
      "Epoch4/10, Training Loss: 0.065, Testing Loss: 0.387, Train Accuracy: 0.982, Test Accuracy: 0.986  \n",
      "Epoch5/10, Training Loss: 0.065, Testing Loss: 0.389, Train Accuracy: 0.982, Test Accuracy: 0.989  \n",
      "Epoch6/10, Training Loss: 0.059, Testing Loss: 0.356, Train Accuracy: 0.983, Test Accuracy: 0.985  \n",
      "Epoch7/10, Training Loss: 0.055, Testing Loss: 0.332, Train Accuracy: 0.984, Test Accuracy: 0.989  \n",
      "Epoch8/10, Training Loss: 0.052, Testing Loss: 0.315, Train Accuracy: 0.985, Test Accuracy: 0.989  \n",
      "Epoch9/10, Training Loss: 0.055, Testing Loss: 0.330, Train Accuracy: 0.985, Test Accuracy: 0.989  \n",
      "Epoch10/10, Training Loss: 0.050, Testing Loss: 0.300, Train Accuracy: 0.985, Test Accuracy: 0.989  \n"
     ]
    }
   ],
   "source": [
    "#Train the CNN\n",
    "\n",
    "num_epochs =10\n",
    "train_loss =[]\n",
    "train_accuracy = []\n",
    "test_loss =[]\n",
    "test_accuracy = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    correct = 0\n",
    "    iterations = 0\n",
    "    iter_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    for i,(inputs,labels) in enumerate(train_load):\n",
    "\n",
    "        if CUDA:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "        outputs = model(inputs) #forward propagation\n",
    "        loss = loss_func(outputs,labels)\n",
    "        iter_loss += loss.item() #extract the value from the tensor\n",
    "\n",
    "        #clear the gradience\n",
    "        optimizer.zero_grad() # w <-- w -lr*gradient\n",
    "\n",
    "        #back propagation\n",
    "        loss.backward()\n",
    "        #update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        #calculate accuracy\n",
    "        _, prediccted = torch.max(outputs,1)\n",
    "        correct += (prediccted == labels).sum().item()\n",
    "        iterations +=1\n",
    "    \n",
    "    train_loss.append(iter_loss/iterations)\n",
    "    train_accuracy.append(correct/ len(train_dataset))\n",
    "\n",
    "    #Testing phase for every epoch\n",
    "    testing_loss = 0.0\n",
    "    correct = 0\n",
    "    iterations = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for i,(inputs,labels) in enumerate(test_load):\n",
    "\n",
    "        if CUDA:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "        outputs = model(inputs) #forward propagation\n",
    "        loss = loss_func(outputs,labels)\n",
    "        testing_loss += loss.item() #extract the value from the tensor\n",
    "\n",
    "        #calculate accuracy\n",
    "        _, prediccted = torch.max(outputs,1)\n",
    "        correct += (prediccted == labels).sum().item()\n",
    "        iterations +=1    \n",
    "\n",
    "\n",
    "    test_loss.append(iter_loss/iterations)\n",
    "    test_accuracy.append(correct/ len(test_dataset))\n",
    "\n",
    "\n",
    "    print(\"Epoch{}/{}, Training Loss: {:.3f}, Testing Loss: {:.3f}, Train Accuracy: {:.3f}, Test Accuracy: {:.3f}  \". format(\n",
    "        epoch+1, num_epochs, train_loss[-1], test_loss[-1], train_accuracy[-1],test_accuracy[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss and accuracy curve\n",
    "f = plt.figure( figsize=(10,10))\n",
    "plt.plot(train_loss, label = \"Train loss\")\n",
    "plt.plot(test_loss, label = \"Test loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "f = plt.figure( figsize=(10,10))\n",
    "plt.plot(train_accuracy, label = \"Train accuracy\")\n",
    "plt.plot(test_accuracy, label = \"Test accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is : 3\n",
      "Actual is : 3\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "img = test_dataset[30][0].resize_((1,1,28,28)) #(batch_size,num_channels,height,width)\n",
    "label = test_dataset[30][1]\n",
    "model.eval()\n",
    "\n",
    "if CUDA:\n",
    "    model.cuda()\n",
    "    img = img.cuda()\n",
    "\n",
    "\n",
    "outputs = model(img)\n",
    "_, predicted = torch.max(outputs,1)\n",
    "print(\"Prediction is : {}\".format(predicted.item()))\n",
    "print(\"Actual is : {}\".format(label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Prediction on my own image\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(image_name, model):\n\u001b[1;32m      5\u001b[0m     image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image_name, \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "# Prediction on my own image\n",
    "import cv2\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def predict(image_name, model):\n",
    "    image = cv2.imread(image_name, 0) # 0 transform to gray scale\n",
    "    ret, thresholded = cv2.threshold(image,127,255,cv2.THRESH_BINARY) #black background and white writting, whatever pixel are over 127 will be equal to 255 and pixels below 127 will be 0\n",
    "    img = 255 - thresholded #background -> write , invert the image\n",
    "    cv2.imshow(\"Original\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    img = Image.formarray(img)\n",
    "    img = trs(img)\n",
    "    img = img.view(1,1,28,28) #resize the image to the expected size of cnn\n",
    "    img = Variable(img) #wrap image to a variable\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    if CUDA:\n",
    "        model = model.cuda()\n",
    "        img = img.cuda()\n",
    "\n",
    "    output = model(img)\n",
    "    _, predicted = torch.max(output,1)\n",
    "    return predicted.item()\n",
    "\n",
    "image_name = test_dataset[30][0].resize_((1,1,28,28))\n",
    "pred = predict(image_name, model)\n",
    "print(pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
